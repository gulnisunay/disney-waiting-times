{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ARDbb1xs4HuB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import time\n",
        "import gc  # Garbage collector for memory management"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Record start time\n",
        "start_time = time.time()\n"
      ],
      "metadata": {
        "id": "ibFT3_GI5SWj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory usage monitoring function\n",
        "def check_memory_usage(step_name=\"\"):\n",
        "    import psutil\n",
        "    process = psutil.Process()\n",
        "    memory_info = process.memory_info()\n",
        "    memory_mb = memory_info.rss / 1024 / 1024\n",
        "    print(f\"Memory usage ({step_name}): {memory_mb:.2f} MB\")\n",
        "\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    # Load data in chunks if file is large\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/proyectoDS/data/all_waiting_times.csv\")\n",
        "    metadata = pd.read_csv(\"/content/drive/MyDrive/proyectoDS/data/overview data/metadata.csv\")\n",
        "    check_memory_usage(\"after loading\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    # Alternative approach with chunking if needed\n",
        "    # df = pd.read_csv(\"all_waiting_times.csv\", chunksize=100000)\n",
        "    # df = pd.concat([chunk for chunk in df])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7bJxX2j-z6s",
        "outputId": "3cb57c7e-3e97-47ae-e0a0-36e8682b9a37"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Memory usage (after loading): 3634.49 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering - focused and memory-efficient\n",
        "print(\"Performing feature engineering...\")\n",
        "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
        "\n",
        "# Basic time features - essential ones only\n",
        "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
        "df[\"minute\"] = df[\"datetime\"].dt.minute\n",
        "df[\"weekday\"] = df[\"datetime\"].dt.day_name()\n",
        "df[\"month\"] = df[\"datetime\"].dt.month\n",
        "df[\"is_weekend\"] = df[\"datetime\"].dt.dayofweek >= 5\n",
        "df[\"date\"] = df[\"datetime\"].dt.date  # Create date column for merging\n",
        "\n",
        "# Most important cyclical features only\n",
        "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve9q5g779L7D",
        "outputId": "311f7c6f-af9c-4b74-c7ab-717a3d2ee428"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing feature engineering...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Free memory - but don't delete datetime yet\n",
        "gc.collect()\n",
        "check_memory_usage(\"after feature engineering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzEPfRHy_rPt",
        "outputId": "43e62207-08a5-4760-d6f1-f5dc6d5b987d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage (after feature engineering): 5100.02 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge only essential metadata\n",
        "metadata[\"DATE\"] = pd.to_datetime(metadata[\"DATE\"]).dt.date\n",
        "df = df.merge(\n",
        "    metadata[[\"DATE\", \"HOLIDAYM\"]], left_on=\"date\", right_on=\"DATE\", how=\"left\"\n",
        ")\n",
        "df[\"HOLIDAYM\"] = df[\"HOLIDAYM\"].fillna(0)\n",
        "\n",
        "# Free memory from unused columns\n",
        "del df[\"DATE\"]\n",
        "del df[\"date\"]\n",
        "del df[\"datetime\"]  # Now it's safe to delete datetime\n",
        "gc.collect()\n",
        "check_memory_usage(\"after metadata merge\")\n",
        "\n",
        "# Handle attraction popularity efficiently\n",
        "attraction_avg_wait = df.groupby(\"attraction\")[\"SPOSTMIN\"].mean().reset_index()\n",
        "attraction_avg_wait.columns = [\"attraction\", \"avg_historical_wait\"]\n",
        "df = df.merge(attraction_avg_wait, on=\"attraction\", how=\"left\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbVMONfs9fNc",
        "outputId": "941ef1ea-bc2d-4d18-ee83-a9620f072864"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage (after metadata merge): 4294.12 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter invalid data\n",
        "print(\"Filtering data...\")\n",
        "df = df[\n",
        "    (df[\"SPOSTMIN\"].notna()) &\n",
        "    (df[\"SPOSTMIN\"] >= 0) &\n",
        "    (df[\"SPOSTMIN\"] < 300)\n",
        "]\n",
        "check_memory_usage(\"after filtering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-CT-q3ADCN",
        "outputId": "e2bb2e57-cbe0-454a-aeea-6386ea48019d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering data...\n",
            "Memory usage (after filtering): 4722.98 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical features - use sparse matrices for efficiency\n",
        "print(\"Encoding categorical features...\")\n",
        "df_encoded = pd.get_dummies(df, columns=[\"weekday\", \"attraction\"], sparse=True)\n",
        "\n",
        "# Prepare features and target\n",
        "print(\"Preparing features...\")\n",
        "feature_cols = [\n",
        "    \"hour\", \"minute\", \"month\", \"HOLIDAYM\", \"is_weekend\",\n",
        "    \"hour_sin\", \"hour_cos\", \"avg_historical_wait\"\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFzkVnOVAKGD",
        "outputId": "8e38284a-5e67-4869-e62b-7e6979649302"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding categorical features...\n",
            "Preparing features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add encoded columns\n",
        "encoded_cols = [col for col in df_encoded.columns if col.startswith((\"weekday_\", \"attraction_\"))]\n",
        "all_feature_cols = feature_cols + encoded_cols\n",
        "\n",
        "# Split data\n",
        "X = df_encoded[all_feature_cols]\n",
        "y = df_encoded[\"SPOSTMIN\"]\n",
        "\n",
        "# Free original dataframe memory\n",
        "del df\n",
        "del df_encoded\n",
        "gc.collect()\n",
        "check_memory_usage(\"after preparing features\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bMIeI0uASlu",
        "outputId": "2216b3ae-8599-4919-ee30-93b03bd6f95b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage (after preparing features): 4983.21 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model with efficient parameters\n",
        "print(\"Training model...\")\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=100,  # Fewer trees for memory efficiency\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,       # Moderate depth\n",
        "    subsample=0.8,     # Use 80% of samples for each tree (reduces memory)\n",
        "    max_features=0.8,  # Use 80% of features for each tree (reduces memory)\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    verbose=1          # Show progress\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqzU470hAv0u",
        "outputId": "0f32d874-ef5d-4d42-959c-b0b4e3cc126c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features for better model performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "check_memory_usage(\"after model training\")\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating model...\")\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "# Feature importance - safely\n",
        "try:\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        feature_names = list(X.columns)\n",
        "        importances = model.feature_importances_\n",
        "\n",
        "        # Ensure lengths match\n",
        "        if len(importances) == len(feature_names):\n",
        "            indices = np.argsort(importances)[::-1]\n",
        "\n",
        "            print(\"\\nTop 10 Important Features:\")\n",
        "            for i in range(min(10, len(indices))):\n",
        "                print(f\"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error getting feature importance: {e}\")\n",
        "check_memory_usage(\"after evaluation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkgG3J2aBC4m",
        "outputId": "5945360d-d5d3-4790-9af0-773b3222084d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1117: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
            "  if np.may_share_memory(array, array_orig):\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1117: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
            "  if np.may_share_memory(array, array_orig):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1         833.9289          77.6198           53.63m\n",
            "         2         769.3780          60.9297           53.67m\n",
            "         3         717.6540          55.3624           52.31m\n",
            "         4         674.0209          41.5545           51.49m\n",
            "         5         641.6699          35.6092           51.71m\n",
            "         6         610.4868          29.6070           50.97m\n",
            "         7         580.7703          28.9713           50.10m\n",
            "         8         557.1795          24.4875           49.29m\n",
            "         9         536.5068          18.6482           48.96m\n",
            "        10         518.3351          21.4314           48.31m\n",
            "        20         429.3569           4.0485           42.75m\n",
            "        30         393.2911           2.2183           38.28m\n",
            "        40         376.5435           1.8852           33.50m\n",
            "        50         365.0206          -0.2102           28.20m\n",
            "        60         357.7319           0.7215           22.71m\n",
            "        70         352.1762           1.0771           17.08m\n",
            "        80         347.8689           0.6848           11.41m\n",
            "        90         344.7006           1.7256            5.72m\n",
            "       100         341.3974           1.0527            0.00s\n",
            "Memory usage (after model training): 8145.23 MB\n",
            "Evaluating model...\n",
            "\n",
            "Model Performance:\n",
            "MAE: 12.65\n",
            "RMSE: 18.44\n",
            "R2 Score: 0.6261\n",
            "\n",
            "Top 10 Important Features:\n",
            "avg_historical_wait: 0.4281\n",
            "attraction_flight_of_passage: 0.0899\n",
            "hour_cos: 0.0701\n",
            "hour: 0.0633\n",
            "attraction_space_mountain: 0.0528\n",
            "month: 0.0420\n",
            "attraction_slinky_dog: 0.0416\n",
            "hour_sin: 0.0376\n",
            "HOLIDAYM: 0.0348\n",
            "attraction_7_dwarfs_train: 0.0209\n",
            "Memory usage (after evaluation): 8185.21 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize without keeping too many points in memory\n",
        "plt.figure(figsize=(10, 8))\n",
        "# Plot smaller samples if dataset is large\n",
        "if len(y_test) > 5000:\n",
        "    sample_indices = np.random.choice(len(y_test), 5000, replace=False)\n",
        "    plt.scatter(y_test.iloc[sample_indices], y_pred[sample_indices], alpha=0.3)\n",
        "else:\n",
        "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
        "plt.xlabel(\"Actual SPOSTMIN\")\n",
        "plt.ylabel(\"Predicted SPOSTMIN\")\n",
        "plt.title(\"Predicted vs Actual Posted Wait Times - Memory-Efficient Model\")\n",
        "plt.plot([0, 300], [0, 300], color=\"red\", linestyle=\"--\")\n",
        "plt.savefig(\"memory_efficient_model_predictions.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "_EUdISA5O_Aw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Distribution - with sampling for large datasets\n",
        "errors = y_pred - y_test\n",
        "plt.figure(figsize=(10, 6))\n",
        "if len(errors) > 10000:\n",
        "    sampled_errors = np.random.choice(errors, 10000, replace=False)\n",
        "    plt.hist(sampled_errors, bins=50)\n",
        "else:\n",
        "    plt.hist(errors, bins=50)\n",
        "plt.xlabel(\"Prediction Error\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Error Distribution\")\n",
        "plt.axvline(x=0, color=\"r\", linestyle=\"-\")\n",
        "plt.savefig(\"memory_efficient_error_distribution.png\")\n",
        "plt.close()\n",
        "check_memory_usage(\"after plotting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7cRz5z5PEIA",
        "outputId": "042fcc62-c625-4ed5-bcca-a0888d29b166"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage (after plotting): 8203.17 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and scaler\n",
        "print(\"Saving model...\")\n",
        "joblib.dump(model, \"memory_efficient_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(list(X.columns), \"model_features.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opWGkxywPKbH",
        "outputId": "292b2030-a350-44b1-bbe6-98505cb6bc3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_features.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print execution time\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"\\nExecution time: {execution_time:.2f} seconds ({execution_time/60:.2f} minutes)\")\n",
        "check_memory_usage(\"end of script\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMT12Qs0PPj_",
        "outputId": "ab0b853d-9b13-4e01-eeb7-36508d628aa7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution time: 4074.45 seconds (67.91 minutes)\n",
            "Memory usage (end of script): 8203.17 MB\n"
          ]
        }
      ]
    }
  ]
}